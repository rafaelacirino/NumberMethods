{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5289e5",
   "metadata": {},
   "source": [
    "# <center>__MÉTODOS NUMÉRICOS__</center>\n",
    "## <center>__PROJETO DA UNIDADE 2__</center>\n",
    "\n",
    "#### <center>__ALUNO: Rafaela Borba Falcão Cirino__</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365a93c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "1. INTRODUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0468101",
   "metadata": {},
   "source": [
    "<p> PCA é um procedimento matemático que utiliza uma transformação ortogonal (ortogonalização de vetores) para converter um conjunto de observações de variáveis possivelmente correlacionadas num conjunto de valores de variáveis linearmente não correlacionadas chamadas de componentes principais. PCA (Principal Component Analysis) robusto é um método que foi abordado na estatística substituindo a estimativa padrão da matriz de covariância por um estimador robusto. Por outro lado, em redes neurais PCA tem deixado robusto designando uma rede neural que dependia em regras auto-organizadas baseadas em física estatística. Mas todos esses métodos robustos ainda são limitados para dados relativamente de baixa dimensão e, portanto, eles não são aplicáveis para aplicações de visão computacional com dados de alta dimensão.</p>\n",
    "<p> PCA tem sido usado com o intuito de modelar o plano de fundo reduzindo significativamente a dimensão dos dados. Para executar o PCA, diferentes PCA robustos têm sido desenvolvidos recentemente. A sequência de plano de fundo é então modelada por um subespaço de baixa classificação que pode mudar gradualmente ao longo do tempo, enquanto os objetos em primeiro plano em movimento constituem os outliers esparsos correlacionados.</p>\n",
    "<p>PCA robusto foi aplicado com grande sucesso em:\n",
    "    <ul>\n",
    "        <li>Imagens e análises de baixo nível;</li>\n",
    "        <li>Imagens médicas, como reconstrução de imagens, análises de imagens do cérebro, imagens cardíacas, entre outras;</li>\n",
    "        <li>Imagens para visão computacional em 3D: requer medição mecânica nas posições da câmera ou alinhamento manual de vistas parciais de uma cena em 3D. Dessa forma, o PCA robusto também pode ser usado para reduzir outliers e ruído em algoritmo como Structure from Motion (SfM), 3D motion recovery e reconstrução em 3D.</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b646b80",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "2. DESCRIÇÃO DO PROBLEMA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835018f",
   "metadata": {},
   "source": [
    "<p>A utilização do uso de PCA robusto, deve-se ao estudo sobre algoritmos para detecção de objetos em movimento em uma cena com fundo estático. Estas cenas, geralmente, estão sob a influência de mudanças na iluminação e sujeitas a presença de sombras. O objetivo do PCA robusto é detectar e segmentar uma mão em movimento sobre um fundo qualquer a partir de uma sequência de imagens em cores, capturadas por uma câmera.</p>\n",
    "<p> A capacidade de detectar objetos em movimento a partir de sequências de vídeo é fundamental em muitos sistemas de visão computacional. Tal capacidade, permite que os sistemas foquem a atenção nos objetos que estão em movimento e que possivelmente são cruciais na execução da tarefa para a qual foram programados. A ideia da subtração de fundo é subtrair da imagem atual uma imagem de referência, a qual é adquirida e modelada a partir de um fundo estático durante certo período de tempo, o que é conhecido como tempo de treinamento. Dessa forma, o fundo pode ser qualquer um, desde que permaneça razoavelmente estático.</p>\n",
    "<p>Desde que a técnica de subtração de fundo foi reconhecida como método de detcção de objetos em movimento, alguns métodos apareceram. alguns algoritmos exploram a dferença estatística e/ou probabilística de cor entre a imagem atual e a imagem de referência, a qual é treinada durante um período de tempo com base em um número determinado de imagens. Outros baseiam-se na análise de movimento dos objetos, nas características das imagens em estéreo, em transformações logarítmicas e no aprendizado por markov e bayesianas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffef2a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "3. MÉTODOS APLICADOS À SOLUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb80a03f",
   "metadata": {},
   "source": [
    "<p>Os métodos que serão usados para aplicação de remoção de undo de imagem, encontram-se a seguir com importações necessárias e funções respectivas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc652d",
   "metadata": {},
   "source": [
    "<p>Primeiro passo: definir uma matriz de dados a partir do vídeo:</p>\n",
    "<p>def create_data_matrix_from_video(clip, k=5, scale=50):</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e4c3b",
   "metadata": {},
   "source": [
    "<p>Em seguida, mudar as cores do vídeo para escala de cinza:</p>\n",
    "<p>def rgb2gray(rgb):</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82158def",
   "metadata": {},
   "source": [
    "<p>Há dois métodos de plotagem de imagens:</p>\n",
    "<p>def plt_images(M, A, E, index_array, dims, filename=None):</p>\n",
    "<p>def plots(ims, dims, figsize=(15,20), rows=1, interp=False, titles=None):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc26aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix_from_video(clip, k=5, scale=50):\n",
    "    return np.vstack([rescale(rgb2gray(clip.get_frame(i/float(k))).astype(int), \n",
    "                      scale).flatten() for i in range(k * int(clip.duration))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c8ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix_from_video(clip, k, scale):\n",
    "    frames = []\n",
    "    for i in range(k * int(clip.duration)):\n",
    "        frame = clip.get_frame(i / float(k))\n",
    "        frame = rgb2gray(frame).astype(int)\n",
    "        image = Image.fromarray(frame)\n",
    "        size = tuple((np.array(image.size) * scale).astype(int))\n",
    "        scaled_image = np.array(image.resize(size)).flatten()\n",
    "        frames.append(scaled_image)\n",
    "    return np.vstack(frames).T # stack images horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9967cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix_from_video(clip, k, scale):\n",
    "    frames = []\n",
    "    for i in range(k * int(clip.duration)):\n",
    "        frame = clip.get_frame(i / float(k))\n",
    "        frame = rgb2gray(frame).astype(int)\n",
    "        image = Image.fromarray(frame)\n",
    "        size = tuple((np.array(image.size) * scale).astype(int))\n",
    "        scaled_image = np.array(image.resize(size)).flatten()\n",
    "        frames.append(scaled_image)\n",
    "    return np.vstack(frames).T # stack images horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f5235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff7824be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_images(M, A, E, index_array, dims, filename=None):\n",
    "    f = plt.figure(figsize=(15, 10))\n",
    "    r = len(index_array)\n",
    "    pics = r * 3\n",
    "    for k, i in enumerate(index_array):\n",
    "        for j, mat in enumerate([M, A, E]):\n",
    "            sp = f.add_subplot(r, 3, 3*k + j + 1)\n",
    "            sp.axis('Off')\n",
    "            pixels = mat[:,i]\n",
    "            if isinstance(pixels, scipy.sparse.csr_matrix):\n",
    "                pixels = pixels.todense()\n",
    "            plt.imshow(np.reshape(pixels, dims), cmap='gray')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726eb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, dims, figsize=(15,20), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims)\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        plt.imshow(np.reshape(ims[i], dims), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49ebff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "4. IMPLEMENTAÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ceea258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /home/rafaela/.local/lib/python3.8/site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /home/rafaela/.local/lib/python3.8/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version != \"2.7\" in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.21.4)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /home/rafaela/.local/lib/python3.8/site-packages (from moviepy) (0.1.9)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0; python_version >= \"3.4\" in /home/rafaela/.local/lib/python3.8/site-packages (from moviepy) (0.4.5)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5; python_version >= \"3.4\" in /home/rafaela/.local/lib/python3.8/site-packages (from moviepy) (2.16.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /home/rafaela/.local/lib/python3.8/site-packages (from moviepy) (4.63.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/lib/python3/dist-packages (from moviepy) (2.22.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/rafaela/.local/lib/python3.8/site-packages (from imageio<3.0,>=2.5; python_version >= \"3.4\"->moviepy) (9.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f554dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /home/rafaela/.local/lib/python3.8/site-packages (0.19.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.21.4)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/rafaela/.local/lib/python3.8/site-packages (from scikit-image) (2.7.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.7.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/rafaela/.local/lib/python3.8/site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/rafaela/.local/lib/python3.8/site-packages (from scikit-image) (9.0.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/rafaela/.local/lib/python3.8/site-packages (from scikit-image) (2.16.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/rafaela/.local/lib/python3.8/site-packages (from scikit-image) (2022.2.9)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea1502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mpe\n",
    "# from IPython.display import display\n",
    "from glob import glob\n",
    "\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b4f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_ITERS = 10\n",
    "TOL = 1.0e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b56dc7a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "MoviePy error: failed to read the duration of file http://backgroundmodelschallenge.eu/.\nHere are the file infos returned by ffmpeg:\n\nffmpeg version 4.2.2-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2019 the FFmpeg developers\n  built with gcc 8 (Debian 8.3.0-6)\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n  libavutil      56. 31.100 / 56. 31.100\n  libavcodec     58. 54.100 / 58. 54.100\n  libavformat    58. 29.100 / 58. 29.100\n  libavdevice    58.  8.100 / 58.  8.100\n  libavfilter     7. 57.100 /  7. 57.100\n  libswscale      5.  5.100 /  5.  5.100\n  libswresample   3.  5.100 /  3.  5.100\n  libpostproc    55.  5.100 / 55.  5.100\nhttp://backgroundmodelschallenge.eu/: Invalid data found when processing input\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36mffmpeg_parse_infos\u001b[0;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_GIF\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"([0-9][0-9]:[0-9][0-9]:[0-9][0-9].[0-9][0-9])\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4949/1460095636.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://backgroundmodelschallenge.eu/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Make a reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mpix_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rgba\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_mask\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"rgb24\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         self.reader = FFMPEG_VideoReader(filename, pix_fmt=pix_fmt,\n\u001b[0m\u001b[1;32m     89\u001b[0m                                          \u001b[0mtarget_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_resolution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                          \u001b[0mresize_algo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresize_algorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         infos = ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[0m\u001b[1;32m     36\u001b[0m                                    fps_source)\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_fps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36mffmpeg_parse_infos\u001b[0;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'duration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvsecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             raise IOError((\"MoviePy error: failed to read the duration of file %s.\\n\"\n\u001b[0m\u001b[1;32m    290\u001b[0m                            \u001b[0;34m\"Here are the file infos returned by ffmpeg:\\n\\n%s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                               filename, infos))\n",
      "\u001b[0;31mOSError\u001b[0m: MoviePy error: failed to read the duration of file http://backgroundmodelschallenge.eu/.\nHere are the file infos returned by ffmpeg:\n\nffmpeg version 4.2.2-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2019 the FFmpeg developers\n  built with gcc 8 (Debian 8.3.0-6)\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n  libavutil      56. 31.100 / 56. 31.100\n  libavcodec     58. 54.100 / 58. 54.100\n  libavformat    58. 29.100 / 58. 29.100\n  libavdevice    58.  8.100 / 58.  8.100\n  libavfilter     7. 57.100 /  7. 57.100\n  libswscale      5.  5.100 /  5.  5.100\n  libswresample   3.  5.100 /  3.  5.100\n  libpostproc    55.  5.100 / 55.  5.100\nhttp://backgroundmodelschallenge.eu/: Invalid data found when processing input\n"
     ]
    }
   ],
   "source": [
    "video = mpe.VideoFileClip(\"http://backgroundmodelschallenge.eu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.subclip(0,50).ipython_display(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c1bb8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "5. CASOS DE USO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 25   # Adjust scale to change resolution of image\n",
    "dims = (int(240 * (scale/100)), int(320 * (scale/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = create_data_matrix_from_video(video, 100, scale)\n",
    "# M = np.load(\"high_res_surveillance_matrix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe716c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dims, M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d053461",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(M[:,140], dims), cmap='gray');plt.imshow(np.reshape(M[:,140], dims), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cd471",
   "metadata": {},
   "source": [
    "<p>De acordo com [3], como a função</p>\n",
    "\n",
    "def create_data_matrix_from_video(clip, k=5, scale=50):\n",
    "<p>é um pouco lenta, salvaremos nossa matriz. Em geral, sempre que houver etapas lentas de pré-processamento, é uma boa idéia salvar os resultados para uso futuro.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"low_res_surveillance_matrix.npy\", M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79456d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(M, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d54eb80",
   "metadata": {},
   "source": [
    "## Usando SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98191301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = decomposition.randomized_svd(M, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e490431",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.shape, s.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rank = u @ np.diag(s) @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6222ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beab3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(low_rank, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(low_rank[:,140], dims), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8160436",
   "metadata": {},
   "source": [
    "<p>Nesse Caso, pode-se perceber apenas o Background.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191cf178",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(M[:,550] - low_rank[:,550], dims), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee589681",
   "metadata": {},
   "source": [
    "<p>Podem ser visualizados apenas carros, ou figuras em movimento. A análise de componentes principais é útil para eliminar dimensões. O PCA clássico busca a melhor estimativa de classificação desta forma, será usada a biblioteca Fast Randomized PCA do Facebook.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fbpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f694f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import fbpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOL=1e-9\n",
    "MAX_ITERS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917739d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converged(Z, d_norm):\n",
    "    err = np.linalg.norm(Z, 'fro') / d_norm\n",
    "    print('error: ', err)\n",
    "    return err < TOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f9733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink(M, tau):\n",
    "    S = np.abs(M) - tau\n",
    "    return np.sign(M) * np.where(S>0, S, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a581c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _svd(M, rank): return fbpca.pca(M, k=min(rank, np.min(M.shape)), raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bd863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_op(M): return _svd(M, 1)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85cc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_reconstruct(M, rank, min_sv):\n",
    "    u, s, v = _svd(M, rank)\n",
    "    s -= min_sv\n",
    "    nnz = (s > 0).sum()\n",
    "    return u[:,:nnz] @ np.diag(s[:nnz]) @ v[:nnz], nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcp(X, maxiter=10, k=10): # refactored\n",
    "    m, n = X.shape\n",
    "    trans = m<n\n",
    "    if trans: X = X.T; m, n = X.shape\n",
    "        \n",
    "    lamda = 1/np.sqrt(m)\n",
    "    op_norm = norm_op(X)\n",
    "    Y = np.copy(X) / max(op_norm, np.linalg.norm( X, np.inf) / lamda)\n",
    "    mu = k*1.25/op_norm; mu_bar = mu * 1e7; rho = k * 1.5\n",
    "    \n",
    "    d_norm = np.linalg.norm(X, 'fro')\n",
    "    L = np.zeros_like(X); sv = 1\n",
    "    \n",
    "    examples = []\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        print(\"rank sv:\", sv)\n",
    "        X2 = X + Y/mu\n",
    "        \n",
    "        # update estimate of Sparse Matrix by \"shrinking/truncating\": original - low-rank\n",
    "        S = shrink(X2 - L, lamda/mu)\n",
    "        \n",
    "        # update estimate of Low-rank Matrix by doing truncated SVD of rank sv & reconstructing.\n",
    "        # count of singular values > 1/mu is returned as svp\n",
    "        L, svp = svd_reconstruct(X2 - S, sv, 1/mu)\n",
    "        \n",
    "        # If svp < sv, you are already calculating enough singular values.\n",
    "        # If not, add 20% (in this case 240) to sv\n",
    "        sv = svp + (1 if svp < sv else round(0.05*n))\n",
    "        \n",
    "        # residual\n",
    "        Z = X - L - S\n",
    "        Y += mu*Z; mu *= rho\n",
    "        \n",
    "        examples.extend([S[140,:], L[140,:]])\n",
    "        \n",
    "        if m > mu_bar: m = mu_bar\n",
    "        if converged(Z, d_norm): break\n",
    "    \n",
    "    if trans: L=L.T; S=S.T\n",
    "    return L, S, examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574c36a",
   "metadata": {},
   "source": [
    "## Resultados Obtidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cf062",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = M.shape\n",
    "round(m * .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78544f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S, examples =  pcp(M, maxiter=5, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt_images(M, S, L, [140], dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28001f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"high_res_L.npy\", L)\n",
    "np.save(\"high_res_S.npy\", S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29144ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt_images(M, S, L, [0, 100, 1000], dims)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
